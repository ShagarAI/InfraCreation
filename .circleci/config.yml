# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

commands:
  # Exercise - Rollback
  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 

          when: on_fail

          command: |
            echo ${CIRCLE_WORKFLOW_ID:0:5} && \
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5}


# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  #say-hello:
  #  # Specify the execution environment. You can specify an image from Dockerhub or use one of our Convenience Images from CircleCI's Developer Hub.
  #  # See: https://circleci.com/docs/2.0/configuration-reference/#docker-machine-macos-windows-executor
  #  docker:
  #    - image: cimg/base:stable
  #  # Add steps to the job
  #  # See: https://circleci.com/docs/2.0/configuration-reference/#steps
  #  steps:
  #    - checkout
  #    - run:
  #        name: "Say hello"
  #        command: "echo Hello, World!"

  InfraCreation:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
              --template-file create_ec2.yml \
              --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} \
              --region us-west-2

      - run:
          name: Installing required workspace utilities (tar,gzip)
          command: |
            yum install -y tar gzip 

      - run:
          name: Creating workspace directory.
          command: |
            mkdir /tmp/workshare

      - run:
          name: Populate Inventory
          command: |
             aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:Project,Values=Udacity" \
              --output text >> /tmp/workshare/inventory

      # Uncomment the following to Deliberately fail it for testing
      #- run: return 1

      - destroy_environment

      - run:
          name: Output inventory file contents    
          command: |
            cat /tmp/workshare/inventory

      - persist_to_workspace:
          root: /tmp/workshare
          paths:
            - inventory*
       
 
  ConfigureInfra:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["73:55:04:ec:10:1b:1b:a0:51:22:92:22:72:c9:64:35"]
      
      - run:
          name: Install Ansible
          command: |
            apk add --update ansible
     
      - attach_workspace:
          at: /tmp/workshare
     
      - run:
          name: Configure EC2 Instance
          command: |
            ansible-playbook -i /tmp/workshare/inventory main-remote.yml 

  smoke_test:
    docker:
      - image: amazon/aws-cli
      #- image: alpine:latest
    steps:
      #- run: apk add --update curl
      #- run: yum install -y curl

      #- run:
      #    name: Get EC2 instance URL
      #    command: |
      #      aws ec2 describe-instances \
      #        --query 'Reservations[*].Instances[*].PublicDnsName' \
      #        --filters "Name=tag:Project,Values=Udacity" \
      #        --output text

      - run:
          name: smoke test
          command: |
            URL="http://"
            URL+=`aws ec2 describe-instances \
                   --query 'Reservations[*].Instances[*].PublicDnsName' \
                   --filters "Name=tag:Project,Values=Udacity" \
                   --output text`
            URL+=":3000"

            # Test if website exists
            if curl -s --head ${URL} 
            then
              exit 0
            else
              exit 1 
            fi
       
      - destroy_environment


  # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file. 
  create_and_deploy_frontend:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file ./S3Bucket/bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if you wish to upload all contents of the [ S3Sync ] directory to the S3 bucket
      - run: aws s3 sync ./S3Bucket/S3Sync s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete

  # Fetch and save the pipeline ID (bucket ID) responsible for the last release.
  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/PipelineID.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - PipelineID.txt 

  # Executes the cloudfront.yml template that will modify the existing CloudFront Distribution, This should change target:
  # from the old bucket to the new bucket - `mybucket-${CIRCLE_WORKFLOW_ID:0:7}`. 
  # Notice here we use the stack name `production-distro` which is the same name we used while deploying to the S3 bucket manually.
  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudfront create-invalidation --distribution-id distribution_ID --paths "/*" && \
            aws cloudformation deploy \
            --template-file ./S3Bucket/cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  # Destroy the previous production version's S3 bucket and CloudFormation stack. 
  clean_up_old_frontend:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/PipelineID.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  say-hello-workflow:
    jobs:
      #- say-hello
      - InfraCreation
      - ConfigureInfra:
          requires:
            - InfraCreation
      - smoke_test:
          requires:
            - ConfigureInfra
      
      - create_and_deploy_frontend
      - promote_to_production:
          requires:
            - create_and_deploy_frontend
      - get_last_deployment_id
      - cleanup_old_frontend:
          requires:
            - get_last_deployment_id
            _ promote_to_production
